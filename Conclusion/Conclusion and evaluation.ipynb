{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness Metrics Comparison and Discussion\n",
    "\n",
    "## Comparison of Fairness Across Datasets\n",
    "\n",
    "We evaluate the fairness of recommendation models (**SVD++** (Movielens & E-commerce), **UserKNN** (Movielens), and **ItemKNN** (E-commerce)) on two distinct datasets: **MovieLens** and **E-commerce**, using a comprehensive set of fairness metrics. While both datasets support recommender system research, they differ in scope, structure, and granularity.\n",
    "\n",
    "### Dataset Differences\n",
    "\n",
    "- **MovieLens** provides a structured dataset with explicit ratings, clear user demographics (gender, age, occupation), and consistent rating behavior, making it highly suitable for recommender system evaluation.\n",
    "- **E-commerce** dataset offers a different domain perspective with product categories and more diverse gender identities, providing insights into commercial recommendation scenarios.\n",
    "- The domain differences (movies vs. products) impact recommendation behavior and fairness interpretation across metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Metric Observations\n",
    "\n",
    "| Metric                         | MovieLens Insights                                               | E-commerce Insights                                              |\n",
    "|-------------------------------|-------------------------------------------------------------------|------------------------------------------------------------------|\n",
    "| **RMSE (Accuracy)**           | SVD++ performs best (0.8830); UserKNN slightly higher (0.8908).   | SVD++: **1.1357**, ItemKNN: **0.9094** — slightly lower error with ItemKNN. |\n",
    "| **Gender-Based RMSE**         | RMSE is higher for **female users** in both models, indicating potential bias. (F: 0.9111 vs M: 0.8738 for SVD++) | SVD++: Female RMSE **1.2206** (+7.5%), Male **1.1211**. Non-binary & fluid identities show significantly lower RMSEs (e.g., Non-binary: **0.5772**). ItemKNN shows similar trends: Female RMSE **0.9955** (+9.5%), Male **0.8437**. |\n",
    "| **Gini Coefficient**          | Moderate inequality in exposure: SVD++ (0.1228), UserKNN slightly better (0.1184). | SVD++: Moderate inequality in exposure (**Gini = 0.5351**) across 24 product categories. Item-KNN shows lower inequality (**0.1194**), though the evaluation was based on fewer categories. |\n",
    "| **Bottom-N Individual Fairness** | Notable disparity: SVD++ bottom 1% avg = 2.3021 vs overall = 3.6623 → Δ = 1.3602 (37.1%). UserKNN shows even larger gap (43.5%). | SVD++: Bottom 1% utility is **3.5081** vs overall **3.9654** (−11.5%). Disparities are consistent across gender (F: −11.4%, M: −11.7%). ItemKNN has extreme disparity: bottom 1% utility is **2.0977** vs overall **3.7608** (−44.2%), with females more affected (−48.1%). |\n",
    "| **N1-Norm Group Fairness (Gender)** | High RMSE distribution divergence for females in both models (e.g., SVD++ F: 0.4269 vs M: 0.1557). | SVD++: RMSE and MAE distributions show high divergence across gender. Female N1-norms: RMSE **5.04**, MAE **4.70**. Male N1-norms: RMSE **5.96**, MAE **5.56**. ItemKNN also shows gender disparity: Female RMSE N1-norm = **5.23**, MAE N1-norm = **7.41** — suggesting greater prediction inconsistencies for female users. |\n",
    "| **KL Divergence (Gender)**    | Low but present divergence in prediction and error distributions (e.g., SVD++ F: 0.0096). | SVD++: Moderate KL divergence in prediction errors across gender (RMSE KL: M = **NaN**, F = **NaN**; MAE KL: M = **NaN**, F = **NaN**). This likely indicates invalid bins in the distribution. ItemKNN shows clearer divergence: RMSE KL: M = **0.2163**, F = **0.0682**; MAE KL: M = **0.3210**, F = **0.1429**. |\n",
    "| **Individual Fairness Variance** | SVD++ shows low variance across users (mean: 0.0143); stable predictions. UserKNN exhibits higher mean variance (0.1168) and outliers (max: 351.03). Younger users tend to have more variability. | SVD++: Very low variance across users (**mean: 0.0082**, max: 0.0542) shows stable recommendations. Item-KNN has higher mean variance (**0.4807**), and **23 users** had extreme variance > 1.0 — indicating less fairness in prediction consistency. |\n",
    "| **Mean Average Envy for Individual Fairness** | SVD++ shows moderate envy (mean: 0.1826); lowest for older groups, highest for Under 18. UserKNN has higher envy (mean: 0.2378), with greatest unfairness for younger users. | SVD++: Envy is very low and consistent (**mean: 0.0606**, max: 0.2408) with no zero-envy users removed. Item-KNN shows significantly higher envy (**mean: 0.5434**, max: 2.0381), and **789 zero-envy users were removed**. **27 users** had extreme envy > 1.0. |\n",
    "| **Fraction of Satisfied Users (FSU)** | Fairly consistent across models and groups. SVD++: 0.5332 overall, with slight gender/age variation. UserKNN: 0.5282 overall, slightly higher satisfaction for older users. | SVD++: Overall satisfaction across groups is moderate (avg FSU ranges ~**0.38–0.48**). Most consistent satisfaction found among users aged 31–40 and with Bachelor’s education. Minor gender variation observed. Item-KNN: Slightly higher satisfaction overall, esp. in groups like Non-binary (**0.67**), Polygender (**0.67**), and 18–25 age group (**0.55**). Income and education disparities remain (Master’s: **0.48** vs Bachelor’s: **0.53**). |\n",
    "| **Absolute Difference (AD) for Group Fairness** | SVD++: Avg AD = 0.2238 (valid for 10.2% of categories); UserKNN higher at 0.2878. Gender imbalance in users: ~2.74:1 (M:F). | SVD++: Avg AD = **0.0373** — showing high group fairness across product categories. Item-KNN is significantly less fair with Avg AD = **0.3413**. Largest disparities found in “Health Care” (**1.19**), “Baby Products” (**0.83**), and “Beauty & Personal Care” (**0.72**). |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The MovieLens dataset provides a structured foundation for recommender system evaluation with explicit ratings and defined demographics, while the E-commerce dataset introduces complexity through broader product categories and diverse user identities. This domain difference significantly influences fairness outcomes.\n",
    "\n",
    "Gender consistently impacts fairness across both datasets, with female users experiencing higher error rates (MovieLens: F: 0.9111 vs M: 0.8738 for SVD++; E-commerce: 7.5–9.5% higher RMSE for females). This suggests systematic biases possibly stemming from imbalanced training data or implicit feedback behaviors.\n",
    "\n",
    "SVD++, as a model-based approach, demonstrates stronger fairness consistency across both datasets, with lower individual fairness variance (MovieLens: 0.0143, E-commerce: 0.0082). For the E-commerce dataset, **ItemKNN** was used instead of UserKNN, which was infeasible due to extreme sparsity in the user-item matrix and insufficient user similarity patterns. However, ItemKNN showed **greater fairness disparities**, with a substantially higher **Absolute Difference score (0.3413)** and extreme **envy values** (max: 2.0381). Individual fairness variance for ItemKNN was also much higher (0.4807), with 23 users showing extreme prediction variability.\n",
    "\n",
    "Gender representation imbalances are noteworthy in both datasets (MovieLens M:F ratio of ~2.74:1). In contrast, the E-commerce dataset had near-equal binary gender representation (449 male, 452 female users) and additionally included **non-binary and gender-diverse identities**. These identities frequently showed **lower RMSE and higher satisfaction rates**, though small sample sizes limit statistical power. For instance, Non-binary users had a relatively low RMSE (0.5772) and higher FSU (0.67), but fairness variance was still observed in envy and variance-based metrics.\n",
    "\n",
    "A significant limitation in the E-commerce evaluation for ItemKNN was its basis on **only 5 product categories**, compared to **24 for SVD++**. The extreme disparities observed in specific categories like **“Health Care” (AD: 1.19)** and **“Baby Products” (AD: 0.83)** underscore that **fairness considerations may need to be domain-specific**, as certain product domains introduce higher bias risks. Moreover, differences in exposure (Gini: 0.5351 for SVD++, 0.1194 for ItemKNN) highlight the trade-off between accuracy, fairness, and coverage when evaluating across domains.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Among the recommendation models evaluated, **SVD++ continues to demonstrate the best overall balance between predictive accuracy and fairness**, performing consistently well across both MovieLens and E-commerce datasets. Its model-based approach enables more stable recommendations, reflected in its **low individual fairness variance** (MovieLens: 0.0143, E-commerce: 0.0082) and **low envy levels**. SVD++ also maintains **greater group fairness**, as evidenced by its substantially **lower Absolute Difference (0.0373)** and **moderate Gini coefficient (0.5351)** in the E-commerce context.\n",
    "\n",
    "**ItemKNN** performs well in terms of **predictive accuracy** in the E-commerce dataset (RMSE: **0.9094** vs SVD++'s **1.1357**), but suffers from **extreme fairness disparities**, including a **67.8% utility gap** for the bottom 1% of users and **much higher envy (mean: 0.5434)**. It also exhibited **greater variance and instability**, particularly among marginalized groups, suggesting lower consistency in user experience.\n",
    "\n",
    "The **inability to apply UserKNN** to the E-commerce dataset underscores the **challenges of sparse and high-dimensional commercial data**, where user similarity patterns are weak or computationally infeasible. This reinforces the importance of aligning algorithm selection with dataset structure and coverage.\n",
    "\n",
    "**Gender-based disparities** persist in both domains. Female users consistently face **higher RMSE and MAE**, as well as higher divergence in prediction distributions. These findings confirm the need for **fairness-aware design strategies** in recommender systems, particularly in datasets with complex or imbalanced demographics. In E-commerce, this imbalance extends beyond binary gender, revealing **disparities in non-binary and minority identities** despite generally lower error rates—indicating that sample size alone can obscure deeper fairness challenges.\n",
    "\n",
    "Ultimately, the **structure and demographic depth of a dataset** strongly influence how fairness manifests and how reliably it can be evaluated. MovieLens offers a clean, controlled benchmark, while the E-commerce dataset exposes real-world complexities, including **domain-specific exposure gaps, broader identity groups**, and **high category imbalance**. Together, they highlight the **need for fairness metrics tailored to the context and user base** of recommender systems in practice.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
